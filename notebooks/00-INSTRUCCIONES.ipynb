{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Agent motion prediction\n",
    "MatÃ­as MacÃ­as GÃ³mez"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Descargar los datos\n",
    "Descargar los datos del siguiente enlace [link descarga ðŸ”—](https://www.kaggle.com/c/lyft-motion-prediction-autonomous-vehicles/data)\n",
    "\n",
    "---\n",
    "\n",
    "## Ejecutar los Notebooks\n",
    "Todos los notebooks se pueden ejetur de manera independiente, los resultados de los predicciones se guardan en la carpeta predicciones.\n",
    "La primer vez que se corren los experimentos se debe generar el dataset de `validationchopped.zarr` por lo cual se deben buscar la celda que contenga el siguiente codigo descomentarlo y ejecutar la celda. Esto solo es necesario hacerlo 1 vez ya que los notebooks solo cargan este nuevo dataset para realizar la evaluaciÃ³n es el dataset cortado.\n",
    "\n",
    "```\n",
    "# ===== GENERATE AND LOAD CHOPPED DATAS\n",
    "num_frames_to_chop = 100\n",
    "eval_cfg = 'scenes/validate.zarr'\n",
    "eval_base_path = create_chopped_dataset(dm.require(eval_cfg[\"key\"]), cfg[\"raster_params\"][\"filter_agents_threshold\"], \n",
    "num_frames_to_chop, cfg[\"model_params\"][\"future_num_frames\"], MIN_FUTURE_STEPS)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Resultados y predicciones obtenidas\n",
    "En la carpeta `notebooks/metrics` estan los resultados de la evaluacion de los diferentes modelos, pero para encontrar las predicciones hay que descargarlas del siguiente link [link descarga ðŸ”—](https://drive.google.com/drive/folders/1UyAsgWjv89Q7dyoKYaraJeQfzuYlB_ZD?usp=sharing) ya que eran demasiado pesadas para ser subidas a github"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}